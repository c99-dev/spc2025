# ë­ì²´ì¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import os
from dotenv import load_dotenv
from langchain_openai import (
    OpenAIEmbeddings,
)

from langchain_community.document_loaders import PyPDFLoader

from langchain.text_splitter import (
    CharacterTextSplitter,
)
from langchain_community.vectorstores import Chroma

import sqlite3

from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers.string import StrOutputParser

load_dotenv()

PERSIST_DIR = "./chroma_db"


# íŒŒì¼ ê²½ë¡œë¥¼ ë°›ì•„ì„œ ë°±í„° DBë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
# PDF íŒŒì¼ì„ ì½ê³ , í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ê³ , ë²¡í„° DBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
# ë§Œì•½ ë°±í„° DBê°€ ì´ë¯¸ ì¡´ì¬í•˜ë©´, ê¸°ì¡´ DBë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜
def create_vector_db(file_path):
    # pdf íŒŒì¼ì¸ì§€ í™•ì¸
    if not file_path.endswith(".pdf"):
        raise ValueError("PDF íŒŒì¼ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")

    if check_collection_exists(PERSIST_DIR, os.path.basename(file_path)):
        print(f"'{os.path.basename(file_path)}' ì»¬ë ‰ì…˜ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
        return

    loader = PyPDFLoader(file_path)
    pages = loader.load()

    print("í˜ì´ì§€ ìˆ˜:", len(pages))
    # print("ìƒ˜í”Œ 1 í˜ì´ì§€", pages[0].page_content)

    for doc in pages:
        doc.metadata["source"] = os.path.basename(file_path)
        if "page" in doc.metadata:
            doc.metadata["page"] = doc.metadata["page"]

    text_splitter = CharacterTextSplitter(
        separator="\n\n", chunk_size=2000, chunk_overlap=200
    )
    texts = text_splitter.split_documents(pages)

    embeddings = OpenAIEmbeddings()

    store = Chroma.from_documents(
        texts,
        embeddings,
        collection_name=os.path.basename(file_path),
        persist_directory=PERSIST_DIR,
    )
    return store


def check_collection_exists(persist_dir, collection_name):
    if not os.path.exists(persist_dir):
        print(f"DB ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {persist_dir}")
        return False

    # sqlite DB íŒŒì¼ì—ì„œ selectí•˜ì—¬ collectionì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    db_file = os.path.join(persist_dir, "chroma.sqlite3")
    if not os.path.exists(db_file):
        print(f"DB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {db_file}")
        return False

    conn = sqlite3.connect(db_file)
    cursor = conn.cursor()
    cursor.execute(
        "SELECT name FROM collections WHERE name=?",
        (collection_name,),
    )
    exists = cursor.fetchone() is not None
    conn.close()
    return exists


def answer_question(question):
    # sqlite DB íŒŒì¼ì—ì„œ selectí•˜ì—¬ ëª¨ë“  collection ì´ë¦„ì„ ê°€ì ¸ì˜´
    db_file = os.path.join(PERSIST_DIR, "chroma.sqlite3")

    if not os.path.exists(db_file):
        print(f"DB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {db_file}")
        return "ë°ì´í„°ë² ì´ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

    conn = sqlite3.connect(db_file)
    cursor = conn.cursor()
    cursor.execute("SELECT name FROM collections")
    collections = cursor.fetchall()
    conn.close()

    if not collections:
        print("DBì— ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
        return "ë°ì´í„°ë² ì´ìŠ¤ì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."

    # ì»¬ë ‰ì…˜ ì´ë¦„ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    collection_names = [collection[0] for collection in collections]

    embeddings = OpenAIEmbeddings()

    stores = {
        name: Chroma(
            persist_directory=PERSIST_DIR,
            embedding_function=embeddings,
            collection_name=name,
        )
        for name in collection_names
    }

    llm = ChatOpenAI(model="gpt-4o-mini")
    prompt = ChatPromptTemplate.from_template(
        """
    ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:

    ë¬¸ì„œë“¤:
    {context}

    ì§ˆë¬¸:
    {question}
    """
    )

    chain = prompt | llm | StrOutputParser()

    def ask(question):
        # ëª¨ë“  ë¬¸ì„œì™€ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
        all_docs_with_scores = []

        # ê° ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰ ê²°ê³¼ì™€ ì ìˆ˜ ìˆ˜ì§‘
        for name, store in stores.items():
            docs_with_scores = store.similarity_search_with_score(question, k=1000)
            all_docs_with_scores.extend(docs_with_scores)

        # ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (ì ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡ ë” ìœ ì‚¬í•¨)
        all_docs_with_scores.sort(key=lambda x: x[1])

        # ìƒìœ„ 5ê°œë§Œ ì‚¬ìš©í•˜ê¸°
        top_docs_with_scores = all_docs_with_scores[:5]

        # ë‹µë³€ ìƒì„±ì„ ìœ„í•œ ë¬¸ì„œ ë‚´ìš©ë§Œ ì¶”ì¶œ
        docs_for_query = [doc for doc, _ in top_docs_with_scores]
        context = "\n".join([doc.page_content for doc in docs_for_query])

        # ë‹µë³€ ìƒì„±
        response = chain.invoke({"context": context, "question": question})

        # ì°¸ê³ í•œ ë¬¸ì„œì™€ ìœ ì‚¬ë„ ì •ë³´ êµ¬ì„±
        reference_info = []
        for doc, score in top_docs_with_scores:
            source = doc.metadata.get("source", "ì•Œ ìˆ˜ ì—†ëŠ” ì¶œì²˜")
            page = doc.metadata.get("page", "í˜ì´ì§€ ì •ë³´ ì—†ìŒ")
            similarity = 1.0 - score  # ìœ ì‚¬ë„ ì ìˆ˜ ë³€í™˜ (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë” ìœ ì‚¬í•¨)
            reference_info.append(
                f"ğŸ“„ ë¬¸ì„œ: {source}, í˜ì´ì§€: {page}, ìœ ì‚¬ë„: {similarity:.2%}"
            )

        # ìµœì¢… ì‘ë‹µ êµ¬ì„± (ê°œí–‰ ì¶”ê°€)
        final_response = f"{response}\n\n"
        final_response += "---\n\n"
        final_response += "# ì°¸ê³ í•œ ë¬¸ì„œ ì •ë³´:\n"
        final_response += "\n".join(reference_info)

        # HTML íƒœê·¸ë¡œ ê°œí–‰ ì ìš©
        final_response = final_response.replace("\n", "<br>")

        return final_response

    return ask(question)


def list_files(directory):
    try:
        files = os.listdir(directory)
        return files
    except FileNotFoundError:
        print(f"ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {directory}")
        return []


def delete_file(file_path):
    # íŒŒì¼ ì´ë¦„ ì¶”ì¶œ
    file_name = os.path.basename(file_path)

    try:
        # Chroma ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©í•˜ì—¬ ì»¬ë ‰ì…˜ ì‚­ì œ
        from langchain_community.vectorstores import Chroma
        import shutil
        import sqlite3

        embeddings = OpenAIEmbeddings()

        # ì»¬ë ‰ì…˜ ID ì¡°íšŒ
        db_file = os.path.join(PERSIST_DIR, "chroma.sqlite3")
        conn = sqlite3.connect(db_file)
        cursor = conn.cursor()
        cursor.execute("SELECT id FROM collections WHERE name=?", (file_name,))
        collection_id = cursor.fetchone()

        # Chroma ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì»¬ë ‰ì…˜ ì‚­ì œ
        db = Chroma(
            persist_directory=PERSIST_DIR,
            embedding_function=embeddings,
            collection_name=file_name,
        )
        db.delete_collection()

        # ì»¬ë ‰ì…˜ IDê°€ ìˆìœ¼ë©´ í•´ë‹¹ í´ë” ì‚­ì œ
        if collection_id:
            collection_folder = os.path.join(PERSIST_DIR, collection_id[0])
            if os.path.exists(collection_folder):
                shutil.rmtree(collection_folder)
                print(f"ì»¬ë ‰ì…˜ í´ë” '{collection_id[0]}'ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

        conn.close()
        print(f"ì»¬ë ‰ì…˜ '{file_name}'ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

        # ë¡œì»¬ íŒŒì¼ ì‚­ì œ
        if os.path.exists(file_path):
            os.remove(file_path)
            print(f"íŒŒì¼ '{file_path}'ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
        else:
            print(f"íŒŒì¼ '{file_path}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return False
    except Exception as e:
        print(f"ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False
